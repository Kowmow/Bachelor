{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T16:40:36.583884Z",
     "start_time": "2024-09-09T16:40:35.800297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from angle_emb import AnglE\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "#Funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#Without Prompts: no need to specify a prompt. Just input a list of strings or a single string.\n",
    "\n",
    "# Initialisiere das AnglE-Modell mit UAE-Large-V1\n",
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls')\n",
    "\n",
    "# Liste der Texte\n",
    "texts = [\n",
    "    'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.',\n",
    "    'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.',\n",
    "    'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume'\n",
    "]\n",
    "\n",
    "# Texte mit dem Modell codieren\n",
    "doc_vecs = angle.encode(texts)\n",
    "\n",
    "# Vergleich der Vektoren und Ausgabe der zugehörigen Texte mit ihrer Kosinus-Ähnlichkeit\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f\"Vergleich zwischen Text {i+1} und Text {j+1}:\")\n",
    "        print(f\"Text {i+1}: {texts[i]}\")\n",
    "        print(f\"Text {j+1}: {texts[j]}\")\n",
    "        print(f\"Kosinus-Ähnlichkeit: {similarity.item()}\\n\")"
   ],
   "id": "410c0c73382fcfe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich zwischen Text 1 und Text 2:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9658278292827439\n",
      "\n",
      "Vergleich zwischen Text 1 und Text 3:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume\n",
      "Kosinus-Ähnlichkeit: 0.9342922266833731\n",
      "\n",
      "Vergleich zwischen Text 2 und Text 3:\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume\n",
      "Kosinus-Ähnlichkeit: 0.9004386113439647\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T16:57:52.700461Z",
     "start_time": "2024-09-09T16:57:51.957231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "# Initialisiere das AnglE-Modell\n",
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls')\n",
    "\n",
    "#funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#With Prompts\n",
    "\n",
    "\n",
    "# Liste der Dokumente als einfache Strings\n",
    "texts = [\n",
    "    'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.',\n",
    "    'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.',\n",
    "    'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume.'\n",
    "]\n",
    "\n",
    "# Dokumente codieren mit Prompt A\n",
    "doc_vecs = angle.encode([{'text': t} for t in texts], to_numpy=True, prompt=Prompts.A)\n",
    "\n",
    "# Vergleich der Anfrage mit jedem Dokument\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f\"Vergleich zwischen Text {i+1} und Text {j+1}:\")\n",
    "        print(f\"Text {i+1}: {texts[i]}\")\n",
    "        print(f\"Text {j+1}: {texts[j]}\")\n",
    "        print(f\"Kosinus-Ähnlichkeit: {similarity.item()}\\n\")\n",
    "        \n",
    "        Prompts.list_prompts()"
   ],
   "id": "d6adc01eb44019f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich zwischen Text 1 und Text 2:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9787534623563109\n",
      "\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "Vergleich zwischen Text 1 und Text 3:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9578784755546029\n",
      "\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "Vergleich zwischen Text 2 und Text 3:\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9406015289053687\n",
      "\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T20:32:26.181944Z",
     "start_time": "2024-09-09T20:32:22.027728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "#funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#Infer LLM-based Models\n",
    "\n",
    "# 1. Lade das Hauptmodell und die LoRA-Gewichte auf der CPU\n",
    "model = AutoModelForCausalLM.from_pretrained('NousResearch/Llama-2-7b-hf', torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-hf')\n",
    "\n",
    "# Lade das LoRA-Modell auf der CPU\n",
    "lora_model = PeftModel.from_pretrained(model, 'SeanLee97/angle-llama-7b-nli-v2', torch_dtype=torch.float16)\n",
    "\n",
    "# 2. Initialisiere AnglE mit dem Modell und den LoRA-Gewichten (ohne CUDA)\n",
    "angle = AnglE.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    pretrained_lora_path='SeanLee97/angle-llama-7b-nli-v2',\n",
    "    pooling_strategy='last',\n",
    "    is_llm=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 3. Vektoren für die Texte erzeugen (mit dem passenden Prompt)\n",
    "#texts = [\n",
    "#    {'text': 'The sky is blue, and the sun is shining bright. The wind gently blows through the trees.'},\n",
    "#    {'text': 'The sky is not blue, and the sun is not shining bright. The wind is not gently blowing through the trees.'},\n",
    "#    {'text': 'The sky appears blue, and the sun shines strongly. A gentle wind moves the trees.'},\n",
    "#    {'text': 'The dog is playing with the ball.'}\n",
    "#]\n",
    "\n",
    "texts = [\n",
    "    {'text': 'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume'},\n",
    "]\n",
    "\n",
    "doc_vecs = angle.encode(texts, prompt=Prompts.A)\n",
    "\n",
    "# 4. Berechne die Kosinus-Ähnlichkeiten zwischen den Texten\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarity.item()}')\n",
    "\n",
    "# 5. Liste alle vordefinierten Prompts auf\n",
    "print('All predefined prompts:', Prompts.list_prompts())"
   ],
   "id": "5b267848a62b6e1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ea4e18cb53c49379b4da4d2148730d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'LlamaForCausalLM' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\peft_model.py:737\u001B[0m, in \u001B[0;36mPeftModel.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    736\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattr__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# defer to nn.Module's logic\u001B[39;00m\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1728\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1729\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'PeftModelForCausalLM' object has no attribute 'encode'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\tuners\\lora\\model.py:356\u001B[0m, in \u001B[0;36mLoraModel.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    355\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 356\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattr__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# defer to nn.Module's logic\u001B[39;00m\n\u001B[0;32m    357\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1728\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1729\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'LoraModel' object has no attribute 'encode'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 26\u001B[0m\n\u001B[0;32m     15\u001B[0m lora_model \u001B[38;5;241m=\u001B[39m PeftModel\u001B[38;5;241m.\u001B[39mfrom_pretrained(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSeanLee97/angle-llama-7b-nli-v2\u001B[39m\u001B[38;5;124m'\u001B[39m, torch_dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat16)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# 2. Vektoren für die Texte erzeugen\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Verwende direkt die ausgegebenen Vektoren\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m#doc_vecs = torch.tensor(angle.encode([\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m#    {'text': 'Der Hund spielt mit dem Ball'}\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#], prompt='Fasse den Satz \"{text}\" in einem Wort zusammen'))\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m doc_vecs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mlora_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m([\n\u001B[0;32m     27\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe sky is blue, and the sun is shining bright. The wind gently blows through the trees.\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     28\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe sky is not blue, and the sun is not shining bright. The wind is not gently blowing through the trees.\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     29\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe sky appears blue, and the sun shines strongly. A gentle wind moves the trees.\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     30\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe dog is playing with the ball.\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m     31\u001B[0m ], prompt\u001B[38;5;241m=\u001B[39mPrompts\u001B[38;5;241m.\u001B[39mA))\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Alternativ kannst du auch hier eigene Texte einfügen\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# texts = [\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m#    'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.',\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# 3. Berechne die Kosinus-Ähnlichkeiten zwischen den Texten\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, dv1 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(doc_vecs):\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\peft_model.py:741\u001B[0m, in \u001B[0;36mPeftModel.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    739\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_model\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# see #1892: prevent infinite recursion if class is not initialized\u001B[39;00m\n\u001B[0;32m    740\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m--> 741\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\tuners\\lora\\model.py:360\u001B[0m, in \u001B[0;36mLoraModel.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# see #1892: prevent infinite recursion if class is not initialized\u001B[39;00m\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m--> 360\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1729\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1727\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1728\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1729\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'LlamaForCausalLM' object has no attribute 'encode'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:42:26.034759Z",
     "start_time": "2024-09-09T21:32:45.497607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "#funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#Infer BiLLM-Model\n",
    "\n",
    "# Setze die Umgebung für BiLLM\n",
    "os.environ['BiLLM_START_INDEX'] = '31'\n",
    "\n",
    "# 1. Initialisiere AnglE mit BiLLM und dem Modell sowie den LoRA-Gewichten (ohne CUDA)\n",
    "angle = AnglE.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    pretrained_lora_path='SeanLee97/bellm-llama-7b-nli',  # Angepasst auf das BiLLM Modell\n",
    "    pooling_strategy='last',\n",
    "    is_llm=True,\n",
    "    apply_billm=True,\n",
    "    billm_model_class='LlamaForCausalLM',\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 2. Vektoren für die Texte erzeugen (mit dem passenden Prompt)\n",
    "texts = [\n",
    "    {'text': 'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume'},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Nutze den BiLLM-Prompt, um die Vektoren zu erzeugen\n",
    "doc_vecs = angle.encode(texts, prompt='The representative word for sentence {text} is:\"')\n",
    "\n",
    "# 3. Berechne die Kosinus-Ähnlichkeiten zwischen den Texten\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarity.item()}')\n",
    "\n",
    "# 4. Liste alle vordefinierten Prompts auf\n",
    "print('All predefined prompts:', Prompts.list_prompts())"
   ],
   "id": "dad892a02ba981a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:LLM detected, automatically set apply_lora=True.If it is wrong, you can manually set `apply_lora`.\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "INFO:BiLLM:Here is the Bi-LlamaModel! BiLLM_START_INDEX=31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca9f4a6c4cc3470494bc6e63b221264c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:Load lora weight from SeanLee97/bellm-llama-7b-nli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54218142b6bd4eccae55e805c247ff5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Finn\\.cache\\huggingface\\hub\\models--SeanLee97--bellm-llama-7b-nli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/160M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5891b7085b4e4c85bf0d0f0cfb8753aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between text 1 and text 2: 0.797877674990915\n",
      "Similarity between text 1 and text 3: 0.95167154252485\n",
      "Similarity between text 2 and text 3: 0.769807873441355\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "All predefined prompts: None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:05:25.168418Z",
     "start_time": "2024-09-09T20:55:31.341615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "# 1. Lade das Hauptmodell und die LoRA-Gewichte auf der CPU\n",
    "model = AutoModelForCausalLM.from_pretrained('NousResearch/Llama-2-7b-hf', torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-hf')\n",
    "\n",
    "# Lade das LoRA-Modell auf der CPU\n",
    "lora_model = PeftModel.from_pretrained(model, 'SeanLee97/angle-llama-7b-nli-v2', torch_dtype=torch.float16)\n",
    "\n",
    "# 2. Initialisiere AnglE mit dem Modell und den LoRA-Gewichten (ohne CUDA)\n",
    "angle = AnglE.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    pretrained_lora_path='SeanLee97/angle-llama-7b-nli-v2',\n",
    "    pooling_strategy='last',\n",
    "    is_llm=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 3. Vektoren für die Texte erzeugen (mit dem passenden Prompt)\n",
    "#texts = [\n",
    "#    {'text': 'The sky is blue, and the sun is shining bright. The wind gently blows through the trees.'},\n",
    "#    {'text': 'The sky is not blue, and the sun is not shining bright. The wind is not gently blowing through the trees.'},\n",
    "#    {'text': 'The sky appears blue, and the sun shines strongly. A gentle wind moves the trees.'},\n",
    "#    {'text': 'The dog is playing with the ball.'}\n",
    "#]\n",
    "\n",
    "texts = [\n",
    "    {'text': 'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume'},\n",
    "]\n",
    "\n",
    "doc_vecs = angle.encode(texts, prompt=Prompts.A)\n",
    "\n",
    "# 4. Berechne die Kosinus-Ähnlichkeiten zwischen den Texten\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarity.item()}')\n",
    "\n",
    "# 5. Liste alle vordefinierten Prompts auf\n",
    "print('All predefined prompts:', Prompts.list_prompts())"
   ],
   "id": "63f0cff6025ff874",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a18548ee758c459499d15890d44ba3a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adapters_weights = torch.load(filename, map_location=torch.device(device))\n",
      "INFO:AnglE:LLM detected, automatically set apply_lora=True.If it is wrong, you can manually set `apply_lora`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "110946c2158b4d37be458bcf6ecb62e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:Load lora weight from SeanLee97/angle-llama-7b-nli-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between text 1 and text 2: 0.6794261320640602\n",
      "Similarity between text 1 and text 3: 0.9498970711361487\n",
      "Similarity between text 2 and text 3: 0.7047534430896022\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "All predefined prompts: None\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T23:14:18.832548Z",
     "start_time": "2024-09-09T23:14:14.849024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Festlegen der Dimension für die Embeddings\n",
    "matryoshka_dim = 1024  # Optionen: 64, 128, 256, 512, 768, 1024\n",
    "\n",
    "# Laden des Modells\n",
    "model = SentenceTransformer(\"aari1995/German_Semantic_V3\", trust_remote_code=True, truncate_dim=matryoshka_dim)\n",
    "\n",
    "# Sätze im gegebenen Format\n",
    "texts = [\n",
    "    {'text': 'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.'},\n",
    "    {'text': 'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume'},\n",
    "]\n",
    "\n",
    "# Extrahiere die Sätze aus dem Wörterbuch\n",
    "sentences = [item['text'] for item in texts]\n",
    "\n",
    "# Berechnen der Embeddings (Verwenden von FP16 für weniger Speicherverbrauch)\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True).half()\n",
    "\n",
    "# Berechne die Kosinus-Ähnlichkeit zwischen den Satz-Embeddings\n",
    "similarities = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "\n",
    "# Ausgabe der Kosinus-Ähnlichkeit im gewünschten Format\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(i+1, len(sentences)):\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarities[i, j].item():.4f}')"
   ],
   "id": "6cee1e6e976abcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between text 1 and text 2: 0.4841\n",
      "Similarity between text 1 and text 3: 0.9434\n",
      "Similarity between text 2 and text 3: 0.4651\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T23:15:00.942840Z",
     "start_time": "2024-09-09T23:14:55.746169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Festlegen der Dimension für die Embeddings\n",
    "matryoshka_dim = 1024  # Optionen: 64, 128, 256, 512, 768, 1024\n",
    "\n",
    "# Laden des Modells\n",
    "model = SentenceTransformer(\"aari1995/German_Semantic_V3\", trust_remote_code=True, truncate_dim=matryoshka_dim)\n",
    "\n",
    "# Sätze im gegebenen Format\n",
    "texts = [\n",
    "{'text': 'Der Himmel ist heute von einem strahlenden, tiefen Blau, das sich in den unendlichen Weiten des Himmels erstreckt und die ganze Atmosphäre in ein beruhigendes Licht taucht. Die Sonne steht hoch am Himmel und scheint mit großer Intensität, ihre Strahlen brechen sich in der Luft und erzeugen funkelnde Reflexionen auf jeder Oberfläche, die sie berührt. Der Wind, der nur schwach weht, gleitet sanft durch die Blätter der Bäume, lässt sie leise rascheln und schwingt in einem zarten Rhythmus, der die Stille des Tages auf angenehme Weise untermalt. Die Natur scheint in völliger Harmonie, als ob der Himmel, die Sonne und der Wind gemeinsam eine symphonische Ruhe ausstrahlen, die den Tag vollkommen erscheinen lässt.'},\n",
    "\n",
    "{'text': 'Der Himmel ist heute keineswegs von einem strahlenden Blau erfüllt, sondern erscheint eher düster und grau, ohne jeglichen Schimmer von Licht, der die Stimmung erhellen könnte. Die Sonne, die normalerweise am Himmel hell und warm leuchtet, ist vollständig verdeckt und wirft keinen einzigen Strahl auf die Erde, wodurch alles unter einem bleiernen, schweren Schatten liegt. Der Wind, der sonst sanft und ruhig durch die Bäume weht, regt sich kaum und erzeugt kein Rascheln in den Blättern, sodass die Umgebung still und drückend wirkt. Nichts an diesem Tag strahlt Harmonie oder Ruhe aus, denn der Himmel, die Sonne und der Wind sind alle in eine fast unheimliche Stille und Dunkelheit gehüllt, die den Tag träge und bedrückend erscheinen lässt.'},\n",
    "\n",
    "{'text': 'Der Himmel erstrahlt heute in einem leuchtenden und intensiven Blau, das sich hoch über uns erstreckt und den Himmel in einer faszinierenden Tiefe erscheinen lässt. Die goldene Sonne, die ihre wärmenden Strahlen unermüdlich auf die Erde schickt, thront majestätisch am Himmel und erfüllt die Luft mit einem leichten, flimmernden Glanz, der jede Landschaft in ein sanftes, warmes Licht taucht. Ein milder Windhauch zieht durch die Kronen der Bäume und bringt die Blätter dazu, ein leises, beruhigendes Geräusch von sich zu geben, das sich mit den anderen sanften Geräuschen der Natur zu einem harmonischen Klangteppich vereint. Alles an diesem Tag wirkt in vollkommener Balance, als ob der Himmel, die Sonne und der Wind ein sorgfältig abgestimmtes Zusammenspiel eingehen, um einen Moment der vollkommenen Ruhe und Schönheit zu erschaffen.'}\n",
    "]\n",
    "\n",
    "# Extrahiere die Sätze aus dem Wörterbuch\n",
    "sentences = [item['text'] for item in texts]\n",
    "\n",
    "# Berechnen der Embeddings (Verwenden von FP16 für weniger Speicherverbrauch)\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True).half()\n",
    "\n",
    "# Berechne die Kosinus-Ähnlichkeit zwischen den Satz-Embeddings\n",
    "similarities = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
    "\n",
    "# Ausgabe der Kosinus-Ähnlichkeit im gewünschten Format\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(i+1, len(sentences)):\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarities[i, j].item():.4f}')"
   ],
   "id": "7b56c68ffb1595b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between text 1 and text 2: 0.6338\n",
      "Similarity between text 1 and text 3: 0.9565\n",
      "Similarity between text 2 and text 3: 0.5654\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a3b6652cf741029"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
