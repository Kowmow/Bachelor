{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T16:40:36.583884Z",
     "start_time": "2024-09-09T16:40:35.800297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from angle_emb import AnglE\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "#Funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#Without Prompts: no need to specify a prompt. Just input a list of strings or a single string.\n",
    "\n",
    "# Initialisiere das AnglE-Modell mit UAE-Large-V1\n",
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls')\n",
    "\n",
    "# Liste der Texte\n",
    "texts = [\n",
    "    'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.',\n",
    "    'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.',\n",
    "    'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume'\n",
    "]\n",
    "\n",
    "# Texte mit dem Modell codieren\n",
    "doc_vecs = angle.encode(texts)\n",
    "\n",
    "# Vergleich der Vektoren und Ausgabe der zugehörigen Texte mit ihrer Kosinus-Ähnlichkeit\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f\"Vergleich zwischen Text {i+1} und Text {j+1}:\")\n",
    "        print(f\"Text {i+1}: {texts[i]}\")\n",
    "        print(f\"Text {j+1}: {texts[j]}\")\n",
    "        print(f\"Kosinus-Ähnlichkeit: {similarity.item()}\\n\")"
   ],
   "id": "410c0c73382fcfe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich zwischen Text 1 und Text 2:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9658278292827439\n",
      "\n",
      "Vergleich zwischen Text 1 und Text 3:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume\n",
      "Kosinus-Ähnlichkeit: 0.9342922266833731\n",
      "\n",
      "Vergleich zwischen Text 2 und Text 3:\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume\n",
      "Kosinus-Ähnlichkeit: 0.9004386113439647\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T16:57:52.700461Z",
     "start_time": "2024-09-09T16:57:51.957231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "# Initialisiere das AnglE-Modell\n",
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls')\n",
    "\n",
    "#funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#With Prompts\n",
    "\n",
    "\n",
    "# Liste der Dokumente als einfache Strings\n",
    "texts = [\n",
    "    'Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.',\n",
    "    'Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.',\n",
    "    'Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume.'\n",
    "]\n",
    "\n",
    "# Dokumente codieren mit Prompt A\n",
    "doc_vecs = angle.encode([{'text': t} for t in texts], to_numpy=True, prompt=Prompts.A)\n",
    "\n",
    "# Vergleich der Anfrage mit jedem Dokument\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f\"Vergleich zwischen Text {i+1} und Text {j+1}:\")\n",
    "        print(f\"Text {i+1}: {texts[i]}\")\n",
    "        print(f\"Text {j+1}: {texts[j]}\")\n",
    "        print(f\"Kosinus-Ähnlichkeit: {similarity.item()}\\n\")\n",
    "        \n",
    "        Prompts.list_prompts()"
   ],
   "id": "d6adc01eb44019f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vergleich zwischen Text 1 und Text 2:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9787534623563109\n",
      "\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "Vergleich zwischen Text 1 und Text 3:\n",
      "Text 1: Der Himmel ist blau und die Sonne scheint hell. Der Wind weht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9578784755546029\n",
      "\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "Vergleich zwischen Text 2 und Text 3:\n",
      "Text 2: Der Himmel ist nicht blau und die Sonne scheint nicht hell. Der Wind weht nicht sanft durch die Bäume.\n",
      "Text 3: Der Himmel zeigt sich in Blau, und die Sonne strahlt stark. Ein sanfter Wind bewegt die Bäume.\n",
      "Kosinus-Ähnlichkeit: 0.9406015289053687\n",
      "\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T23:58:25.272518Z",
     "start_time": "2024-09-09T22:55:48.310448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "#funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#Infer LLM-based Models\n",
    "\n",
    "# 1. Lade das Hauptmodell und die LoRA-Gewichte auf der CPU\n",
    "model = AutoModelForCausalLM.from_pretrained('NousResearch/Llama-2-7b-hf', torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-hf')\n",
    "\n",
    "# Lade das LoRA-Modell auf der CPU\n",
    "lora_model = PeftModel.from_pretrained(model, 'SeanLee97/angle-llama-7b-nli-v2', torch_dtype=torch.float16)\n",
    "\n",
    "# 2. Initialisiere AnglE mit dem Modell und den LoRA-Gewichten (ohne CUDA)\n",
    "angle = AnglE.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    pretrained_lora_path='SeanLee97/angle-llama-7b-nli-v2',\n",
    "    pooling_strategy='last',\n",
    "    is_llm=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 3. Vektoren für die Texte erzeugen (mit dem passenden Prompt)\n",
    "#texts = [\n",
    "#    {'text': 'The sky is blue, and the sun is shining bright. The wind gently blows through the trees.'},\n",
    "#    {'text': 'The sky is not blue, and the sun is not shining bright. The wind is not gently blowing through the trees.'},\n",
    "#    {'text': 'The sky appears blue, and the sun shines strongly. A gentle wind moves the trees.'},\n",
    "#    {'text': 'The dog is playing with the ball.'}\n",
    "#]\n",
    "\n",
    "texts = [\n",
    "{'text': 'Der Himmel ist heute von einem strahlenden, tiefen Blau, das sich in den unendlichen Weiten des Himmels erstreckt und die ganze Atmosphäre in ein beruhigendes Licht taucht. Die Sonne steht hoch am Himmel und scheint mit großer Intensität, ihre Strahlen brechen sich in der Luft und erzeugen funkelnde Reflexionen auf jeder Oberfläche, die sie berührt. Der Wind, der nur schwach weht, gleitet sanft durch die Blätter der Bäume, lässt sie leise rascheln und schwingt in einem zarten Rhythmus, der die Stille des Tages auf angenehme Weise untermalt. Die Natur scheint in völliger Harmonie, als ob der Himmel, die Sonne und der Wind gemeinsam eine symphonische Ruhe ausstrahlen, die den Tag vollkommen erscheinen lässt.'},\n",
    "\n",
    "{'text': 'Der Himmel ist heute keineswegs von einem strahlenden Blau erfüllt, sondern erscheint eher düster und grau, ohne jeglichen Schimmer von Licht, der die Stimmung erhellen könnte. Die Sonne, die normalerweise am Himmel hell und warm leuchtet, ist vollständig verdeckt und wirft keinen einzigen Strahl auf die Erde, wodurch alles unter einem bleiernen, schweren Schatten liegt. Der Wind, der sonst sanft und ruhig durch die Bäume weht, regt sich kaum und erzeugt kein Rascheln in den Blättern, sodass die Umgebung still und drückend wirkt. Nichts an diesem Tag strahlt Harmonie oder Ruhe aus, denn der Himmel, die Sonne und der Wind sind alle in eine fast unheimliche Stille und Dunkelheit gehüllt, die den Tag träge und bedrückend erscheinen lässt.'},\n",
    "\n",
    "{'text': 'Der Himmel erstrahlt heute in einem leuchtenden und intensiven Blau, das sich hoch über uns erstreckt und den Himmel in einer faszinierenden Tiefe erscheinen lässt. Die goldene Sonne, die ihre wärmenden Strahlen unermüdlich auf die Erde schickt, thront majestätisch am Himmel und erfüllt die Luft mit einem leichten, flimmernden Glanz, der jede Landschaft in ein sanftes, warmes Licht taucht. Ein milder Windhauch zieht durch die Kronen der Bäume und bringt die Blätter dazu, ein leises, beruhigendes Geräusch von sich zu geben, das sich mit den anderen sanften Geräuschen der Natur zu einem harmonischen Klangteppich vereint. Alles an diesem Tag wirkt in vollkommener Balance, als ob der Himmel, die Sonne und der Wind ein sorgfältig abgestimmtes Zusammenspiel eingehen, um einen Moment der vollkommenen Ruhe und Schönheit zu erschaffen.'}\n",
    "]\n",
    "\n",
    "doc_vecs = angle.encode(texts, prompt=Prompts.A)\n",
    "\n",
    "# 4. Berechne die Kosinus-Ähnlichkeiten zwischen den Texten\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarity.item()}')\n",
    "\n",
    "# 5. Liste alle vordefinierten Prompts auf\n",
    "print('All predefined prompts:', Prompts.list_prompts())"
   ],
   "id": "5b267848a62b6e1e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1403f8b052ef4d14a8e5959183862cc2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:488: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adapters_weights = torch.load(filename, map_location=torch.device(device))\n",
      "INFO:AnglE:LLM detected, automatically set apply_lora=True.If it is wrong, you can manually set `apply_lora`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42aed632355e4194b9a3667dcde9c3ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:Load lora weight from SeanLee97/angle-llama-7b-nli-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between text 1 and text 2: 0.7057046310147344\n",
      "Similarity between text 1 and text 3: 0.9733137911047959\n",
      "Similarity between text 2 and text 3: 0.6712661127194575\n",
      "Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\n",
      "Prompts.B = 'You can only output one word. Summarize \"{text}\":\"'\n",
      "Prompts.C = 'Represent this sentence for searching relevant passages: {text}'\n",
      "All predefined prompts: None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T00:12:50.964187Z",
     "start_time": "2024-09-10T00:12:46.705837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from angle_emb import AnglE, Prompts\n",
    "from angle_emb.utils import cosine_similarity\n",
    "\n",
    "#funktioniert\n",
    "#https://github.com/SeanLee97/AnglE\n",
    "#Infer BiLLM-Model\n",
    "\n",
    "# Setze die Umgebung für BiLLM\n",
    "os.environ['BiLLM_START_INDEX'] = '31'\n",
    "\n",
    "# 1. Initialisiere AnglE mit BiLLM und dem Modell sowie den LoRA-Gewichten (ohne CUDA)\n",
    "angle = AnglE.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    pretrained_lora_path='SeanLee97/bellm-llama-7b-nli',  # Angepasst auf das BiLLM Modell\n",
    "    pooling_strategy='last',\n",
    "    is_llm=True,\n",
    "    apply_billm=True,\n",
    "    billm_model_class='LlamaForCausalLM',\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 2. Vektoren für die Texte erzeugen (mit dem passenden Prompt)\n",
    "texts = [\n",
    "{'text': 'Der Himmel ist heute von einem strahlenden, tiefen Blau, das sich in den unendlichen Weiten des Himmels erstreckt und die ganze Atmosphäre in ein beruhigendes Licht taucht. Die Sonne steht hoch am Himmel und scheint mit großer Intensität, ihre Strahlen brechen sich in der Luft und erzeugen funkelnde Reflexionen auf jeder Oberfläche, die sie berührt. Der Wind, der nur schwach weht, gleitet sanft durch die Blätter der Bäume, lässt sie leise rascheln und schwingt in einem zarten Rhythmus, der die Stille des Tages auf angenehme Weise untermalt. Die Natur scheint in völliger Harmonie, als ob der Himmel, die Sonne und der Wind gemeinsam eine symphonische Ruhe ausstrahlen, die den Tag vollkommen erscheinen lässt.'},\n",
    "\n",
    "{'text': 'Der Himmel ist heute keineswegs von einem strahlenden Blau erfüllt, sondern erscheint eher düster und grau, ohne jeglichen Schimmer von Licht, der die Stimmung erhellen könnte. Die Sonne, die normalerweise am Himmel hell und warm leuchtet, ist vollständig verdeckt und wirft keinen einzigen Strahl auf die Erde, wodurch alles unter einem bleiernen, schweren Schatten liegt. Der Wind, der sonst sanft und ruhig durch die Bäume weht, regt sich kaum und erzeugt kein Rascheln in den Blättern, sodass die Umgebung still und drückend wirkt. Nichts an diesem Tag strahlt Harmonie oder Ruhe aus, denn der Himmel, die Sonne und der Wind sind alle in eine fast unheimliche Stille und Dunkelheit gehüllt, die den Tag träge und bedrückend erscheinen lässt.'},\n",
    "\n",
    "{'text': 'Der Himmel erstrahlt heute in einem leuchtenden und intensiven Blau, das sich hoch über uns erstreckt und den Himmel in einer faszinierenden Tiefe erscheinen lässt. Die goldene Sonne, die ihre wärmenden Strahlen unermüdlich auf die Erde schickt, thront majestätisch am Himmel und erfüllt die Luft mit einem leichten, flimmernden Glanz, der jede Landschaft in ein sanftes, warmes Licht taucht. Ein milder Windhauch zieht durch die Kronen der Bäume und bringt die Blätter dazu, ein leises, beruhigendes Geräusch von sich zu geben, das sich mit den anderen sanften Geräuschen der Natur zu einem harmonischen Klangteppich vereint. Alles an diesem Tag wirkt in vollkommener Balance, als ob der Himmel, die Sonne und der Wind ein sorgfältig abgestimmtes Zusammenspiel eingehen, um einen Moment der vollkommenen Ruhe und Schönheit zu erschaffen.'}\n",
    "]\n",
    "\n",
    "# Nutze den BiLLM-Prompt, um die Vektoren zu erzeugen\n",
    "doc_vecs = angle.encode(texts, prompt='The representative word for sentence {text} is:\"')\n",
    "\n",
    "# 3. Berechne die Kosinus-Ähnlichkeiten zwischen den Texten\n",
    "for i, dv1 in enumerate(doc_vecs):\n",
    "    for j, dv2 in enumerate(doc_vecs[i+1:], start=i+1):\n",
    "        similarity = cosine_similarity(dv1, dv2)\n",
    "        print(f'Similarity between text {i+1} and text {j+1}: {similarity.item()}')\n",
    "\n",
    "# 4. Liste alle vordefinierten Prompts auf\n",
    "print('All predefined prompts:', Prompts.list_prompts())"
   ],
   "id": "dad892a02ba981a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AnglE:LLM detected, automatically set apply_lora=True.If it is wrong, you can manually set `apply_lora`.\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "INFO:BiLLM:Here is the Bi-LlamaModel! BiLLM_START_INDEX=31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "800bc54ec6e643be95cb67ca27817026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "INFO:AnglE:Load lora weight from SeanLee97/bellm-llama-7b-nli\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "C:\\Users\\Finn\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2068: UserWarning: for base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'base_model.model.model.model.embed_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBiLLM_START_INDEX\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m31\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# 1. Initialisiere AnglE mit BiLLM und dem Modell sowie den LoRA-Gewichten (ohne CUDA)\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m angle \u001B[38;5;241m=\u001B[39m \u001B[43mAnglE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mNousResearch/Llama-2-7b-hf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_lora_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSeanLee97/bellm-llama-7b-nli\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Angepasst auf das BiLLM Modell\u001B[39;49;00m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpooling_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlast\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_llm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mapply_billm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbillm_model_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLlamaForCausalLM\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat16\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# 2. Vektoren für die Texte erzeugen (mit dem passenden Prompt)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m texts \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     26\u001B[0m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDer Himmel ist heute von einem strahlenden, tiefen Blau, das sich in den unendlichen Weiten des Himmels erstreckt und die ganze Atmosphäre in ein beruhigendes Licht taucht. Die Sonne steht hoch am Himmel und scheint mit großer Intensität, ihre Strahlen brechen sich in der Luft und erzeugen funkelnde Reflexionen auf jeder Oberfläche, die sie berührt. Der Wind, der nur schwach weht, gleitet sanft durch die Blätter der Bäume, lässt sie leise rascheln und schwingt in einem zarten Rhythmus, der die Stille des Tages auf angenehme Weise untermalt. Die Natur scheint in völliger Harmonie, als ob der Himmel, die Sonne und der Wind gemeinsam eine symphonische Ruhe ausstrahlen, die den Tag vollkommen erscheinen lässt.\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[0;32m     27\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDer Himmel erstrahlt heute in einem leuchtenden und intensiven Blau, das sich hoch über uns erstreckt und den Himmel in einer faszinierenden Tiefe erscheinen lässt. Die goldene Sonne, die ihre wärmenden Strahlen unermüdlich auf die Erde schickt, thront majestätisch am Himmel und erfüllt die Luft mit einem leichten, flimmernden Glanz, der jede Landschaft in ein sanftes, warmes Licht taucht. Ein milder Windhauch zieht durch die Kronen der Bäume und bringt die Blätter dazu, ein leises, beruhigendes Geräusch von sich zu geben, das sich mit den anderen sanften Geräuschen der Natur zu einem harmonischen Klangteppich vereint. Alles an diesem Tag wirkt in vollkommener Balance, als ob der Himmel, die Sonne und der Wind ein sorgfältig abgestimmtes Zusammenspiel eingehen, um einen Moment der vollkommenen Ruhe und Schönheit zu erschaffen.\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m     31\u001B[0m ]\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\angle_emb\\angle.py:1298\u001B[0m, in \u001B[0;36mAnglE.from_pretrained\u001B[1;34m(model_name_or_path, pretrained_model_path, pretrained_lora_path, is_llm, pooling_strategy, train_mode, **kwargs)\u001B[0m\n\u001B[0;32m   1267\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m   1268\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pretrained\u001B[39m(model_name_or_path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   1269\u001B[0m                     pretrained_model_path: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1273\u001B[0m                     train_mode: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1274\u001B[0m                     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1275\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1276\u001B[0m \u001B[38;5;124;03m    Load AnglE from pretrained model.\u001B[39;00m\n\u001B[0;32m   1277\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1296\u001B[0m \u001B[38;5;124;03m            angle.encode(*args, **kwargs)\u001B[39;00m\n\u001B[0;32m   1297\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1298\u001B[0m     angle \u001B[38;5;241m=\u001B[39m \u001B[43mAnglE\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1299\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mis_llm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_llm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1300\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mpretrained_model_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1301\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mpretrained_lora_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrained_lora_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1302\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mpooling_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpooling_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1303\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mtrain_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1304\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1305\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m angle\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\angle_emb\\angle.py:1154\u001B[0m, in \u001B[0;36mAnglE.__init__\u001B[1;34m(self, model_name_or_path, tokenizer_name_or_path, max_length, model_kwargs, lora_config_kwargs, pooling_strategy, apply_lora, train_mode, load_kbit, is_llm, pretrained_model_path, pretrained_lora_path, torch_dtype, device, kbit_kwargs, tokenizer_padding_side, apply_billm, billm_model_class, **kwargs)\u001B[0m\n\u001B[0;32m   1152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pretrained_lora_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1153\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoad lora weight from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_lora_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1154\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mPeftModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_lora_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_kbit\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat16\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_trainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_mode\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m train_mode:\n\u001B[0;32m   1162\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_modules\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m lora_config \u001B[38;5;129;01mor\u001B[39;00m lora_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_modules\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\peft_model.py:545\u001B[0m, in \u001B[0;36mPeftModel.from_pretrained\u001B[1;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, **kwargs)\u001B[0m\n\u001B[0;32m    540\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    541\u001B[0m     model \u001B[38;5;241m=\u001B[39m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config\u001B[38;5;241m.\u001B[39mtask_type](\n\u001B[0;32m    542\u001B[0m         model, config, adapter_name, autocast_adapter_dtype\u001B[38;5;241m=\u001B[39mautocast_adapter_dtype\n\u001B[0;32m    543\u001B[0m     )\n\u001B[1;32m--> 545\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_adapter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapter_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_trainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_trainable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mautocast_adapter_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mautocast_adapter_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    547\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\peft_model.py:1151\u001B[0m, in \u001B[0;36mPeftModel.load_adapter\u001B[1;34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, **kwargs)\u001B[0m\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1147\u001B[0m     device_map \u001B[38;5;241m=\u001B[39m infer_auto_device_map(\n\u001B[0;32m   1148\u001B[0m         \u001B[38;5;28mself\u001B[39m, max_memory\u001B[38;5;241m=\u001B[39mmax_memory, no_split_module_classes\u001B[38;5;241m=\u001B[39mno_split_module_classes\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[1;32m-> 1151\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_offload\u001B[49m\u001B[43m(\u001B[49m\u001B[43moffload_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapters_weights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1152\u001B[0m dispatch_model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moffload_index\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m offload_index\n\u001B[0;32m   1154\u001B[0m dispatch_model(\n\u001B[0;32m   1155\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1156\u001B[0m     device_map\u001B[38;5;241m=\u001B[39mdevice_map,\n\u001B[0;32m   1157\u001B[0m     offload_dir\u001B[38;5;241m=\u001B[39moffload_dir,\n\u001B[0;32m   1158\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdispatch_model_kwargs,\n\u001B[0;32m   1159\u001B[0m )\n",
      "File \u001B[1;32m~\\Work\\Bachelor\\Bachelor\\venv\\Lib\\site-packages\\peft\\peft_model.py:1028\u001B[0m, in \u001B[0;36mPeftModel._update_offload\u001B[1;34m(self, offload_index, adapters_weights)\u001B[0m\n\u001B[0;32m   1026\u001B[0m suffix_pos \u001B[38;5;241m=\u001B[39m safe_key\u001B[38;5;241m.\u001B[39mrfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1027\u001B[0m extended_prefix \u001B[38;5;241m=\u001B[39m prefix \u001B[38;5;241m+\u001B[39m block_id \u001B[38;5;241m+\u001B[39m safe_key[:suffix_pos]\n\u001B[1;32m-> 1028\u001B[0m safe_module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnamed_modules\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mextended_prefix\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(safe_module, BaseTunerLayer):\n\u001B[0;32m   1030\u001B[0m     final_key \u001B[38;5;241m=\u001B[39m extended_prefix \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.base_layer\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m safe_key[suffix_pos:]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'base_model.model.model.model.embed_tokens'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:51:35.084872Z",
     "start_time": "2024-09-09T22:51:33.935355Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "a2333f528ab0d70c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "a739cdbdaa8e430f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
